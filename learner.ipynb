{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP learning for bot (conservative twitter bot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "import seaborn as cb\n",
    "import json\n",
    "import numpy as np\n",
    "import nltk \n",
    "from nltk import bigrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_con = []\n",
    "\n",
    "#scrape data and append tweets to list\n",
    "for i, tweet in enumerate(sntwitter.TwitterSearchScraper('#conservative').get_items()): # declare a username\n",
    "  if i>2000: #number of tweets you want to scrape\n",
    "    break\n",
    "  tweets_con.append([tweet.content]) # declare the attributes to be returned\n",
    "\n",
    "# creating a dataframe from the list\n",
    "tweets_con_df = pd.DataFrame(tweets_con, columns=['Text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating json of tweets for preservation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tweets_con' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m file \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtweet_con.json\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m j \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mdumps(tweets_con, default \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m)\n\u001b[0;32m      3\u001b[0m file\u001b[39m.\u001b[39mwrite(j)\n\u001b[0;32m      4\u001b[0m file\u001b[39m.\u001b[39mclose()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tweets_con' is not defined"
     ]
    }
   ],
   "source": [
    "file = open(\"tweet_con.json\",'w')\n",
    "j = json.dumps(tweets_con, default = str)\n",
    "file.write(j)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(txt):\n",
    "    cleaned = re.sub(r\"http\\S+\",\"\", txt)\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text = [clean_text(elements) for elements in tweets_con_df.Text]\n",
    "tt = TweetTokenizer()\n",
    "normalize = [tt.tokenize(elements.lower()) for elements in cleaned_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.add('#conservative')\n",
    "\n",
    "# remove stop words and punctuation\n",
    "complete = [[w for w in words if not w in stop_words if w.isalnum()] for words in normalize]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2cb316dc1cb7649520000078faeeab63ab4993f92669687fc181249e534c3ab9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
